"""
JSONãƒ‡ãƒ¼ã‚¿å‡¦ç†é–¢æ•°ï¼ˆapp_with_auth.pyäº’æ›ç‰ˆï¼‰
"""
import os
import json
import pandas as pd
from datetime import datetime
import shutil
from typing import Dict, Optional, Any, List


# JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
JSON_PATH = "route-subject-text-time.json"
DEFAULT_STUDENT = "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç”Ÿå¾’"


def load_json_data(user_filter=None):
    """JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€DataFrameã¨ã—ã¦è¿”ã™
    
    Args:
        user_filter: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼è¾æ›¸ {'ç”Ÿå¾’': 'username'} ã¾ãŸã¯ Noneï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰
    
    Returns:
        pd.DataFrame: é€²æ—ãƒ‡ãƒ¼ã‚¿
    """
    if not os.path.exists(JSON_PATH):
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        create_initial_json_data()
    
    try:
        with open(JSON_PATH, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # progress ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã«å¤‰æ›
        if 'progress' in data and data['progress']:
            df = pd.DataFrame(data['progress'])
        else:
            # ç©ºã®DataFrameã‚’ä½œæˆï¼ˆå¿…è¦ãªåˆ—ã‚’å®šç¾©ï¼‰
            df = pd.DataFrame(columns=[
                'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«', 'ç§‘ç›®', 'å‚è€ƒæ›¸å', 'æ‰€è¦æ™‚é–“', 'äºˆå®š', 'é”æˆæ¸ˆ', 
                'é”æˆå‰²åˆ', 'ç”Ÿå¾’', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'æ ¡èˆ'
            ])
        
        # å¿…è¦ãªåˆ—ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        required_columns = ['äºˆå®š', 'é”æˆæ¸ˆ', 'é”æˆå‰²åˆ', 'ç”Ÿå¾’', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'æ ¡èˆ']
        for col in required_columns:
            if col not in df.columns:
                if col in ['äºˆå®š', 'é”æˆæ¸ˆ']:
                    df[col] = False
                elif col == 'ç”Ÿå¾’':
                    df[col] = DEFAULT_STUDENT
                else:
                    df[col] = ''
        
        # ãƒ‡ãƒ¼ã‚¿å‹ã®èª¿æ•´
        if not df.empty:
            df['é”æˆå‰²åˆ'] = df['é”æˆå‰²åˆ'].fillna('').astype(str)
            df.loc[df['é”æˆå‰²åˆ'] == 'nan', 'é”æˆå‰²åˆ'] = ''
            df['ç”Ÿå¾’'] = df['ç”Ÿå¾’'].fillna(DEFAULT_STUDENT).astype(str)
            df.loc[df['ç”Ÿå¾’'] == 'nan', 'ç”Ÿå¾’'] = DEFAULT_STUDENT
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
        if user_filter and not df.empty:
            for column, value in user_filter.items():
                if column in df.columns:
                    df = df[df[column] == value]
        
        return df
        
    except (json.JSONDecodeError, FileNotFoundError, KeyError) as e:
        print(f"âŒ JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç©ºã®DataFrameã‚’è¿”ã™
        return pd.DataFrame(columns=[
            'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«', 'ç§‘ç›®', 'å‚è€ƒæ›¸å', 'æ‰€è¦æ™‚é–“', 'äºˆå®š', 'é”æˆæ¸ˆ', 
            'é”æˆå‰²åˆ', 'ç”Ÿå¾’', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼å', 'æ ¡èˆ'
        ])


def save_json_data(df):
    """DataFrameã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
    
    Args:
        df: ä¿å­˜ã™ã‚‹DataFrame
        
    Returns:
        bool: ä¿å­˜æˆåŠŸãƒ•ãƒ©ã‚°
    """
    try:
        # ä¿å­˜å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ
        if os.path.exists(JSON_PATH):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"route-subject-text-time_backup_{timestamp}.json"
            shutil.copy2(JSON_PATH, backup_path)
            print(f"ğŸ“„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")
        
        # DataFrameã®åŸºæœ¬ãƒã‚§ãƒƒã‚¯
        if df.empty:
            print("âš ï¸ è­¦å‘Š: ç©ºã®DataFrameã‚’ä¿å­˜ã—ã‚ˆã†ã¨ã—ã¦ã„ã¾ã™")
            # ç©ºã®å ´åˆã§ã‚‚åŸºæœ¬æ§‹é€ ã¯ä¿å­˜
            data = {
                "metadata": {
                    "created": datetime.now().isoformat(),
                    "last_updated": datetime.now().isoformat(),
                    "version": "2.0"
                },
                "students": [],
                "books": [],
                "progress": []
            }
        else:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            existing_data = {}
            if os.path.exists(JSON_PATH):
                try:
                    with open(JSON_PATH, 'r', encoding='utf-8') as f:
                        existing_data = json.load(f)
                except:
                    existing_data = {}
            
            # DataFrameã‹ã‚‰JSONãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
            progress_data = df.to_dict('records')
            
            # ç”Ÿå¾’ãƒªã‚¹ãƒˆã‚’æŠ½å‡º
            students = list(df['ç”Ÿå¾’'].unique()) if 'ç”Ÿå¾’' in df.columns else []
            students = [s for s in students if s and s != 'nan']
            
            # å‚è€ƒæ›¸ãƒªã‚¹ãƒˆã‚’æŠ½å‡º
            books = []
            if 'å‚è€ƒæ›¸å' in df.columns and 'ç§‘ç›®' in df.columns:
                book_groups = df.groupby(['ç§‘ç›®', 'å‚è€ƒæ›¸å']).first()
                for (subject, book_name), row in book_groups.iterrows():
                    books.append({
                        "name": book_name,
                        "subject": subject,
                        "time_hours": row.get('æ‰€è¦æ™‚é–“', 0),
                        "route_level": row.get('ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«', '')
                    })
            
            # JSONãƒ‡ãƒ¼ã‚¿æ§‹é€ 
            data = {
                "metadata": {
                    "created": existing_data.get("metadata", {}).get("created", datetime.now().isoformat()),
                    "last_updated": datetime.now().isoformat(),
                    "version": "2.0",
                    "record_count": len(progress_data)
                },
                "students": existing_data.get("students", students),
                "books": existing_data.get("books", books),
                "progress": progress_data
            }
        
        print(f"ğŸ’¾ ä¿å­˜é–‹å§‹: {len(data.get('progress', []))} è¡Œã®ãƒ‡ãƒ¼ã‚¿")
        
        # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        with open(JSON_PATH, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜å¾Œã®ç¢ºèª
        if os.path.exists(JSON_PATH):
            file_size = os.path.getsize(JSON_PATH)
            print(f"âœ… ä¿å­˜å®Œäº†: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º {file_size} bytes")
        
        return True
        
    except Exception as e:
        print(f"âŒ JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def add_new_book_data(df, route_level, subject, book_name, time_hours, current_user, user_campus=''):
    """æ–°ã—ã„å‚è€ƒæ›¸ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    
    Args:
        df: æ—¢å­˜ã®DataFrame
        route_level: ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«
        subject: ç§‘ç›®
        book_name: å‚è€ƒæ›¸å
        time_hours: æ‰€è¦æ™‚é–“
        current_user: ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼
        user_campus: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ ¡èˆ
        
    Returns:
        pd.DataFrame: æ›´æ–°ã•ã‚ŒãŸDataFrame
    """
    new_data = {
        'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«': route_level,
        'ç§‘ç›®': subject,
        'å‚è€ƒæ›¸å': book_name,
        'æ‰€è¦æ™‚é–“': time_hours,
        'äºˆå®š': False,
        'é”æˆæ¸ˆ': False,
        'é”æˆå‰²åˆ': '',
        'ç”Ÿå¾’': current_user,
        'ãƒ¦ãƒ¼ã‚¶ãƒ¼å': current_user,
        'æ ¡èˆ': user_campus
    }
    
    # æ–°ã—ã„è¡Œã‚’DataFrameã«è¿½åŠ 
    new_df = pd.concat([df, pd.DataFrame([new_data])], ignore_index=True)
    return new_df


def update_progress_data(df, index, column, value):
    """é€²æ—ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
    
    Args:
        df: DataFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        index: æ›´æ–°ã™ã‚‹è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        column: æ›´æ–°ã™ã‚‹åˆ—å
        value: æ–°ã—ã„å€¤
        
    Returns:
        pd.DataFrame: æ›´æ–°ã•ã‚ŒãŸDataFrame
    """
    if 0 <= index < len(df):
        df.iloc[index, df.columns.get_loc(column)] = value
        
        # é”æˆæ¸ˆã¿ã‚’æ›´æ–°ã—ãŸå ´åˆã€é”æˆå‰²åˆã‚‚è‡ªå‹•æ›´æ–°
        if column == 'é”æˆæ¸ˆ' and value:
            df.iloc[index, df.columns.get_loc('é”æˆå‰²åˆ')] = '100%'
        elif column == 'é”æˆæ¸ˆ' and not value:
            df.iloc[index, df.columns.get_loc('é”æˆå‰²åˆ')] = ''
    
    return df


def delete_book_data(df, index):
    """å‚è€ƒæ›¸ãƒ‡ãƒ¼ã‚¿ã‚’å‰Šé™¤
    
    Args:
        df: DataFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        index: å‰Šé™¤ã™ã‚‹è¡Œã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        
    Returns:
        pd.DataFrame: å‰Šé™¤å¾Œã®DataFrame
    """
    if 0 <= index < len(df):
        df = df.drop(index=index).reset_index(drop=True)
    
    return df


def initialize_user_data(username, campus=''):
    """æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆæœŸåŒ–
    
    Args:
        username: ãƒ¦ãƒ¼ã‚¶ãƒ¼å
        campus: æ ¡èˆå
    """
    df = load_json_data()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
    user_data = df[df['ç”Ÿå¾’'] == username] if not df.empty else pd.DataFrame()
    
    if user_data.empty:
        print(f"ğŸ‘¤ æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{username}ã€ã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        sample_books = [
            {'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«': 'åŸºç¤', 'ç§‘ç›®': 'æ•°å­¦', 'å‚è€ƒæ›¸å': 'æ•°å­¦Iãƒ»AåŸºç¤å•é¡Œç²¾è¬›', 'æ‰€è¦æ™‚é–“': 80},
            {'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«': 'åŸºç¤', 'ç§‘ç›®': 'è‹±èª', 'å‚è€ƒæ›¸å': 'ã‚·ã‚¹ãƒ†ãƒ è‹±å˜èª', 'æ‰€è¦æ™‚é–“': 60},
            {'ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«': 'åŸºç¤', 'ç§‘ç›®': 'å›½èª', 'å‚è€ƒæ›¸å': 'ç¾ä»£æ–‡èª­è§£åŠ›ã®é–‹ç™ºè¬›åº§', 'æ‰€è¦æ™‚é–“': 40}
        ]
        
        for book in sample_books:
            df = add_new_book_data(
                df, 
                book['ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«'], 
                book['ç§‘ç›®'], 
                book['å‚è€ƒæ›¸å'], 
                book['æ‰€è¦æ™‚é–“'], 
                username, 
                campus
            )
        
        # ä¿å­˜
        save_json_data(df)
        print(f"âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã€Œ{username}ã€ã®åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸ")


def create_initial_json_data():
    """åˆæœŸJSONãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    initial_data = {
        "metadata": {
            "created": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat(),
            "version": "2.0",
            "description": "å­¦ç¿’é€²æ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  - JSONãƒ‡ãƒ¼ã‚¿"
        },
        "students": [DEFAULT_STUDENT],
        "books": [
            {
                "name": "æ•°å­¦Iãƒ»AåŸºç¤å•é¡Œç²¾è¬›",
                "subject": "æ•°å­¦",
                "time_hours": 80,
                "route_level": "åŸºç¤"
            },
            {
                "name": "ã‚·ã‚¹ãƒ†ãƒ è‹±å˜èª",
                "subject": "è‹±èª", 
                "time_hours": 60,
                "route_level": "åŸºç¤"
            },
            {
                "name": "ç¾ä»£æ–‡èª­è§£åŠ›ã®é–‹ç™ºè¬›åº§",
                "subject": "å›½èª",
                "time_hours": 40,
                "route_level": "åŸºç¤"
            }
        ],
        "progress": [
            {
                "ãƒ«ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«": "åŸºç¤",
                "ç§‘ç›®": "æ•°å­¦",
                "å‚è€ƒæ›¸å": "æ•°å­¦Iãƒ»AåŸºç¤å•é¡Œç²¾è¬›",
                "æ‰€è¦æ™‚é–“": 80,
                "äºˆå®š": True,
                "é”æˆæ¸ˆ": False,
                "é”æˆå‰²åˆ": "30%",
                "ç”Ÿå¾’": DEFAULT_STUDENT,
                "ãƒ¦ãƒ¼ã‚¶ãƒ¼å": DEFAULT_STUDENT,
                "æ ¡èˆ": ""
            }
        ]
    }
    
    with open(JSON_PATH, 'w', encoding='utf-8') as f:
        json.dump(initial_data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ“Š åˆæœŸJSONãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸ: {JSON_PATH}")


def get_user_statistics(username):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
    
    Args:
        username: ãƒ¦ãƒ¼ã‚¶ãƒ¼å
        
    Returns:
        dict: çµ±è¨ˆæƒ…å ±
    """
    df = load_json_data({'ç”Ÿå¾’': username})
    
    if df.empty:
        return {
            'total_books': 0,
            'completed_books': 0,
            'in_progress_books': 0,
            'completion_rate': 0.0,
            'subjects': []
        }
    
    total_books = len(df)
    completed_books = len(df[df['é”æˆæ¸ˆ'] == True])
    in_progress_books = len(df[df['äºˆå®š'] == True]) - completed_books
    completion_rate = (completed_books / total_books * 100) if total_books > 0 else 0.0
    subjects = list(df['ç§‘ç›®'].unique()) if 'ç§‘ç›®' in df.columns else []
    
    return {
        'total_books': total_books,
        'completed_books': completed_books,
        'in_progress_books': in_progress_books,
        'completion_rate': round(completion_rate, 1),
        'subjects': subjects
    }


# äº’æ›æ€§ã®ãŸã‚ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹
load_csv_data = load_json_data
save_csv_data = save_json_data